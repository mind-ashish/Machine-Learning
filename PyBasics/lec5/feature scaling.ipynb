{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "from sklearn import datasets\n",
    "boston=datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling to put data in a range: make mean=0, var=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaled_data_orig=preprocessing.scale(boston.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "scaled_data=pd.DataFrame(scaled_data_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling is done before test-train split\n",
    "#scale both train & test data: first train by fit_transform\n",
    "#then test before generating score by transform fn\n",
    "#record scaling factor for each column/feature of train data & scale test date each col by corresponding factor it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(scaled_data,boston.target,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clf=LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7789410172622857"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train)\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit calculate & remember scale for each feauture by keeping mean & S.D for each col.\n",
    "#fit_transform does fit + transform data\n",
    "#transform use above resilt to scale test data.\n",
    "#inverse transform -> scaled to orig data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(boston.data,boston.target,random_state=1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.790000e+02</td>\n",
       "      <td>3.790000e+02</td>\n",
       "      <td>3.790000e+02</td>\n",
       "      <td>3.790000e+02</td>\n",
       "      <td>3.790000e+02</td>\n",
       "      <td>3.790000e+02</td>\n",
       "      <td>3.790000e+02</td>\n",
       "      <td>3.790000e+02</td>\n",
       "      <td>3.790000e+02</td>\n",
       "      <td>3.790000e+02</td>\n",
       "      <td>3.790000e+02</td>\n",
       "      <td>3.790000e+02</td>\n",
       "      <td>3.790000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.108758e-16</td>\n",
       "      <td>-7.235490e-17</td>\n",
       "      <td>2.740405e-15</td>\n",
       "      <td>-1.611142e-17</td>\n",
       "      <td>-3.331255e-15</td>\n",
       "      <td>5.069237e-15</td>\n",
       "      <td>2.502835e-15</td>\n",
       "      <td>-2.938503e-17</td>\n",
       "      <td>-1.652152e-16</td>\n",
       "      <td>4.569783e-17</td>\n",
       "      <td>2.225309e-14</td>\n",
       "      <td>6.262800e-15</td>\n",
       "      <td>-8.105507e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001322e+00</td>\n",
       "      <td>1.001322e+00</td>\n",
       "      <td>1.001322e+00</td>\n",
       "      <td>1.001322e+00</td>\n",
       "      <td>1.001322e+00</td>\n",
       "      <td>1.001322e+00</td>\n",
       "      <td>1.001322e+00</td>\n",
       "      <td>1.001322e+00</td>\n",
       "      <td>1.001322e+00</td>\n",
       "      <td>1.001322e+00</td>\n",
       "      <td>1.001322e+00</td>\n",
       "      <td>1.001322e+00</td>\n",
       "      <td>1.001322e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.057110e-01</td>\n",
       "      <td>-4.910617e-01</td>\n",
       "      <td>-1.567085e+00</td>\n",
       "      <td>-2.984635e-01</td>\n",
       "      <td>-1.436849e+00</td>\n",
       "      <td>-3.925267e+00</td>\n",
       "      <td>-2.222142e+00</td>\n",
       "      <td>-1.261847e+00</td>\n",
       "      <td>-9.773068e-01</td>\n",
       "      <td>-1.289036e+00</td>\n",
       "      <td>-2.748566e+00</td>\n",
       "      <td>-4.000567e+00</td>\n",
       "      <td>-1.549137e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.974710e-01</td>\n",
       "      <td>-4.910617e-01</td>\n",
       "      <td>-8.687452e-01</td>\n",
       "      <td>-2.984635e-01</td>\n",
       "      <td>-9.056987e-01</td>\n",
       "      <td>-5.545832e-01</td>\n",
       "      <td>-8.393110e-01</td>\n",
       "      <td>-8.100591e-01</td>\n",
       "      <td>-6.333892e-01</td>\n",
       "      <td>-7.573090e-01</td>\n",
       "      <td>-5.041135e-01</td>\n",
       "      <td>1.991451e-01</td>\n",
       "      <td>-7.978046e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.801970e-01</td>\n",
       "      <td>-4.910617e-01</td>\n",
       "      <td>-2.228356e-01</td>\n",
       "      <td>-2.984635e-01</td>\n",
       "      <td>-1.365933e-01</td>\n",
       "      <td>-1.219587e-01</td>\n",
       "      <td>3.700019e-01</td>\n",
       "      <td>-2.373698e-01</td>\n",
       "      <td>-5.187500e-01</td>\n",
       "      <td>-4.500892e-01</td>\n",
       "      <td>2.907968e-01</td>\n",
       "      <td>3.769991e-01</td>\n",
       "      <td>-1.335635e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.300721e-02</td>\n",
       "      <td>2.654927e-01</td>\n",
       "      <td>1.001990e+00</td>\n",
       "      <td>-2.984635e-01</td>\n",
       "      <td>5.942692e-01</td>\n",
       "      <td>5.175098e-01</td>\n",
       "      <td>8.958671e-01</td>\n",
       "      <td>6.012837e-01</td>\n",
       "      <td>1.659395e+00</td>\n",
       "      <td>1.540932e+00</td>\n",
       "      <td>8.051504e-01</td>\n",
       "      <td>4.237116e-01</td>\n",
       "      <td>5.804438e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.096097e+00</td>\n",
       "      <td>3.771217e+00</td>\n",
       "      <td>2.405951e+00</td>\n",
       "      <td>3.350493e+00</td>\n",
       "      <td>2.693374e+00</td>\n",
       "      <td>3.676980e+00</td>\n",
       "      <td>1.106567e+00</td>\n",
       "      <td>3.887417e+00</td>\n",
       "      <td>1.659395e+00</td>\n",
       "      <td>1.806795e+00</td>\n",
       "      <td>1.646820e+00</td>\n",
       "      <td>4.313108e-01</td>\n",
       "      <td>3.460665e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  3.790000e+02  3.790000e+02  3.790000e+02  3.790000e+02  3.790000e+02   \n",
       "mean  -1.108758e-16 -7.235490e-17  2.740405e-15 -1.611142e-17 -3.331255e-15   \n",
       "std    1.001322e+00  1.001322e+00  1.001322e+00  1.001322e+00  1.001322e+00   \n",
       "min   -4.057110e-01 -4.910617e-01 -1.567085e+00 -2.984635e-01 -1.436849e+00   \n",
       "25%   -3.974710e-01 -4.910617e-01 -8.687452e-01 -2.984635e-01 -9.056987e-01   \n",
       "50%   -3.801970e-01 -4.910617e-01 -2.228356e-01 -2.984635e-01 -1.365933e-01   \n",
       "75%   -1.300721e-02  2.654927e-01  1.001990e+00 -2.984635e-01  5.942692e-01   \n",
       "max    9.096097e+00  3.771217e+00  2.405951e+00  3.350493e+00  2.693374e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  3.790000e+02  3.790000e+02  3.790000e+02  3.790000e+02  3.790000e+02   \n",
       "mean   5.069237e-15  2.502835e-15 -2.938503e-17 -1.652152e-16  4.569783e-17   \n",
       "std    1.001322e+00  1.001322e+00  1.001322e+00  1.001322e+00  1.001322e+00   \n",
       "min   -3.925267e+00 -2.222142e+00 -1.261847e+00 -9.773068e-01 -1.289036e+00   \n",
       "25%   -5.545832e-01 -8.393110e-01 -8.100591e-01 -6.333892e-01 -7.573090e-01   \n",
       "50%   -1.219587e-01  3.700019e-01 -2.373698e-01 -5.187500e-01 -4.500892e-01   \n",
       "75%    5.175098e-01  8.958671e-01  6.012837e-01  1.659395e+00  1.540932e+00   \n",
       "max    3.676980e+00  1.106567e+00  3.887417e+00  1.659395e+00  1.806795e+00   \n",
       "\n",
       "                 10            11            12  \n",
       "count  3.790000e+02  3.790000e+02  3.790000e+02  \n",
       "mean   2.225309e-14  6.262800e-15 -8.105507e-16  \n",
       "std    1.001322e+00  1.001322e+00  1.001322e+00  \n",
       "min   -2.748566e+00 -4.000567e+00 -1.549137e+00  \n",
       "25%   -5.041135e-01  1.991451e-01 -7.978046e-01  \n",
       "50%    2.907968e-01  3.769991e-01 -1.335635e-01  \n",
       "75%    8.051504e-01  4.237116e-01  5.804438e-01  \n",
       "max    1.646820e+00  4.313108e-01  3.460665e+00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaling is done on x only on both train & test, while fit or predict or score.\n",
    "x_train_scaled=scaler.fit_transform(x_train)\n",
    "x_test_scaled=scaler.transform(x_test)\n",
    "df=pd.DataFrame(x_train_scaled)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
