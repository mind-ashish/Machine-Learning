{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLabelData(column):\n",
    "    first_cut = column.quantile(0.25)\n",
    "    second_cut = column.quantile(0.5)\n",
    "    third_cut = column.quantile(0.75)\n",
    "    for i in range(0, len(column)):\n",
    "        if (column[i] < first_cut):\n",
    "            column[i] = \"vl\"\n",
    "        elif (column[i] < second_cut):\n",
    "            column[i] = \"l\"\n",
    "        elif (column[i] < third_cut):\n",
    "            column[i] = \"h\"\n",
    "        else:\n",
    "            column[i] = \"vh\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, Y):\n",
    "    counts = {}\n",
    "    class_values = set(Y)\n",
    "    for current_class in class_values:\n",
    "        counts[current_class] = {}\n",
    "        rows_with_current_class = (Y == current_class)\n",
    "        X_current_class = X[rows_with_current_class]\n",
    "        Y_current_class = Y[rows_with_current_class]\n",
    "        counts[current_class][\"total_count\"] = len(Y_current_class)\n",
    "        for i in range(X_current_class.shape[1]):\n",
    "            counts[current_class][i] = {}\n",
    "            feature_vals = set(X[:,i])\n",
    "            for val in feature_vals:\n",
    "                counts[current_class][i][val] = (X_current_class[:,i] == val).sum()\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSingleClassProb(x, counts, c):\n",
    "    ans = 1\n",
    "    pr_class = counts[c][\"total_count\"]\n",
    "    ans = ans * pr_class\n",
    "    for i in range(len(x)):\n",
    "        #pr_this_feature = counts[c][i][x[i]]/counts[c][\"total_count\"]\n",
    "        a = len(counts[c][i].keys())\n",
    "        pr_this_feature = (counts[c][i][x[i]] + 1)/(a + counts[c][\"total_count\"])\n",
    "        ans = ans * pr_this_feature\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSingle(x, counts):\n",
    "    max_pr = 0\n",
    "    max_class = None\n",
    "    classes = counts.keys()\n",
    "    for c in classes:\n",
    "        p = findSingleClassProb(x, counts, c)\n",
    "        if p > max_pr:\n",
    "            max_pr = p\n",
    "            max_class = c\n",
    "    return max_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test, counts):\n",
    "    output = []\n",
    "    for x in x_test:\n",
    "        output.append(predictSingle(x, counts))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    makeLabelData(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = fit(df.values, Y)\n",
    "y_pred = predict(df.values, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'total_count': 50,\n",
       "  0: {'vl': 28, 'vh': 0, 'l': 21, 'h': 1},\n",
       "  1: {'vl': 1, 'vh': 33, 'l': 1, 'h': 15},\n",
       "  2: {'vl': 37, 'vh': 0, 'l': 13, 'h': 0},\n",
       "  3: {'vl': 34, 'vh': 0, 'l': 16, 'h': 0}},\n",
       " 1: {'total_count': 50,\n",
       "  0: {'vl': 3, 'vh': 11, 'l': 18, 'h': 18},\n",
       "  1: {'vl': 21, 'vh': 2, 'l': 13, 'h': 14},\n",
       "  2: {'vl': 0, 'vh': 1, 'l': 25, 'h': 24},\n",
       "  3: {'vl': 0, 'vh': 1, 'l': 15, 'h': 34}},\n",
       " 2: {'total_count': 50,\n",
       "  0: {'vl': 1, 'vh': 31, 'l': 2, 'h': 16},\n",
       "  1: {'vl': 11, 'vh': 8, 'l': 10, 'h': 21},\n",
       "  2: {'vl': 0, 'vh': 41, 'l': 0, 'h': 9},\n",
       "  3: {'vl': 0, 'vh': 45, 'l': 0, 'h': 5}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 48,  2],\n",
       "       [ 0,  3, 47]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred, y_true=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.94      0.96      0.95        50\n",
      "           2       0.96      0.94      0.95        50\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=y_pred, y_true=Y))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
