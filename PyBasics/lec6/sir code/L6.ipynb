{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 14), (506,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "x = boston.data\n",
    "y = boston.target\n",
    "x = np.insert(x, 0, 1, axis=1)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.insert(x, 0, 1, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x, y, m):\n",
    "    return ((y - np.dot(x, m)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(x, y, learning_rate, m):\n",
    "    k = x.shape[0]\n",
    "    n = x.shape[1]\n",
    "    batch_size = 10\n",
    "    num_batches = math.ceil(k/batch_size)\n",
    "    for a in range(num_batches):\n",
    "        slope_m = np.zeros(m.shape)\n",
    "        for j in range(n):\n",
    "            start_row = batch_size * a\n",
    "            end_row = min(batch_size * (a + 1), k)\n",
    "            for i in range(start_row, end_row):\n",
    "                y_pred_current = x[i].dot(m)\n",
    "                y_actual = y[i]\n",
    "                slope_m[j] += (2/k)*x[i][j]*(y_pred_current - y_actual)\n",
    "        m = m - learning_rate*slope_m\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, learning_rate=0.1, num_iter =1000):\n",
    "    m = np.zeros(x.shape[1])\n",
    "    print(\"start:\", cost(x, y, m))\n",
    "    for i in range(num_iter):\n",
    "        m = step_gradient(x, y, learning_rate, m)\n",
    "        if (i % (num_iter//10) == 0):\n",
    "            print(i, \":\", cost(x, y, m))\n",
    "    print(\"end:\", cost(x, y, m))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(x, y):\n",
    "    learning_rate = 0.00003\n",
    "    num_iter = 10000\n",
    "    m = gradient_descent(x, y, learning_rate, num_iter)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 578.6537730870713\n",
      "0 : 85.56825753337148\n",
      "1000 : 51.70231489147447\n",
      "2000 : 47.54018194513133\n",
      "3000 : 45.4339863436552\n",
      "4000 : 43.96524754724757\n",
      "5000 : 42.77227297978875\n",
      "6000 : 41.72829075829077\n",
      "7000 : 40.783168734771394\n",
      "8000 : 39.91465491293065\n",
      "9000 : 39.1113241903481\n",
      "end: 38.366919556179596\n"
     ]
    }
   ],
   "source": [
    "#basically fit fn\n",
    "m = run(x_train, y_train)     #run fn needs x_train & y_train as arguement to generate array of slopes i.e m\n",
    "     #m is similar to  (alg.fit which takes xtrain,ytrain & generate slope & intercept on given data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19088742, -0.09217805,  0.10467217, -0.00343187,  0.18865942,\n",
       "        0.08280182,  1.90193994,  0.07640658, -0.21728718,  0.14425685,\n",
       "       -0.01016681,  0.4215816 ,  0.02002361, -0.71764863])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y, y_pred):\n",
    "    u = ((y - y_pred)**2).sum()\n",
    "    d = ((y - y.mean())**2).sum()\n",
    "    return 1 - u/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#basically yp\n",
    "pred = x_test.dot(m)       #using m , we can predict yp =mx+b or pred=x_test.dot(m) here\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5844289853118011"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#basically alg.score\n",
    "score(y_test, pred)   #this is our own score fn , which takes arguement y_test & ypredict as it don't generate ypredict \n",
    "                        #like alg.score ,but simply calculate score by formula. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77902577491373193"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
