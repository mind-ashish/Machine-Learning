{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kerasAndAllNeuralNetwork.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "qjaF889yIcC2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#All about neural networks:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PdTj9OG5HsWe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Neural network: basics: \n",
        "#using layer in b/w to make a difficult fn like xor\n",
        "#using mlp classifier in sklearn."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7fFbkbGdH1g1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Using tensorflow : using forward and backward propagation code, \n",
        "#input , hidden and output layers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ajM1i0qeIA3C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#using cnn for images : writing forward propagation code is req only\n",
        "#using input, convolution layers, pooling layers, stride ,padding\n",
        "#hidden/dense layers and output layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DMN8jbTEIOrQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Using keras as alternative for neural network, cnn, tensorflow."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gqloBGlRIZ_o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wsDI2H5Ykjlq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#keras is neural network library"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ij0lvIWglOHH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#keras mainly uses tensorflow, or others in backend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f1rph57JlrBX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#steps:\n",
        "#1. create a model\n",
        "#2. define architecture: \n",
        "#decide how many layers to use(basically hidden layers and output layers only),\n",
        "#decide no of units in each layer\n",
        "#decide the activation function\n",
        "#decide the weights \n",
        "\n",
        "#extra::\n",
        "#decide whther u want biases\n",
        "#decide whether u want regularisation in each layer\n",
        "#decide whether u want to initialise ur weights(genarally we intiailise with:\n",
        "#random/0/1 value) or not.\n",
        "\n",
        "#regualrisation, initialising weights is not important here.\n",
        "\n",
        "#3. Compile : decide what optimizer and loss fuction to use\n",
        "#4.fit : decide no of iteration, learning rate, echos and batch-size.\n",
        "#5. evaluate or predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x7kwoSWspKvW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#types of models in keras:\n",
        "#most typical model is sequential model: it has many layers, and output \n",
        "#of 1 layer simply goes to other layer\n",
        "\n",
        "#2. Functional API model : it is a bit complex."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Wf93PaeSdFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YqqdqlxCSe6c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Using keras for tensorflow**"
      ]
    },
    {
      "metadata": {
        "id": "mDYabtPXpiY9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential    #importing the sequential model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0UdVrPh4prda",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=Sequential()   #creating the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "861rJMX6pw9r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u-0H5q5OqDE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "breastCancer=datasets.load_breast_cancer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OIh2dF0YqHjY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2023
        },
        "outputId": "20edc9b0-26c0-4db2-b17d-196f2c107cbd"
      },
      "cell_type": "code",
      "source": [
        "print(breastCancer.DESCR)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry \n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
            "        13 is Radius SE, field 23 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7a3sWjBDq88t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#so there are 569 rows , 30 columns/features in dataset and we are predicting whther the user has breast cancer or not"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7TUFpnOrrSeK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "7eaee0cb-d0f7-4883-908d-55f89ca2f026"
      },
      "cell_type": "code",
      "source": [
        "breastCancer.target    #it has binary output class 0,1 "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "oLomlxDzrYMz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#1.need to decide no of layers(hidden and output)\n",
        "#2. No of units in each layer\n",
        "#3. Weights\n",
        "#4. Activation functions: if we don't give our own, it uses identity fn as \n",
        "#activation fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QFB6o6bTt5iO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#since no of features/columns =30 in this dataset\n",
        "\n",
        "#we consider there are 30 inputs for our neural network\n",
        "#or we can say input layer has 30 units"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dRFfMvZvuI90",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Since input layer has 30 units, lets take 32 units in first hidden layer\n",
        "#therefore 16 units in next/second hidden layer, and 1 unit in next layer i.e output layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kg6toGo8uYaM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#so we have input layer with 30 units, 2 hidden layers with 32 and 16 units\n",
        "#and a output layer with 1 unit.\n",
        "\n",
        "#So weights between our input layer to first hidden layer mapping will be\n",
        "#of shape 30*32, first layer to second hidden layer of shape 32*16\n",
        "#second hidden layer to output layer 16*1.\n",
        "\n",
        "#In general we use activation function='relu' for all hidden layers and\n",
        "#activation function='sigmoid' for output layer.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JUCFEM_ewAKD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#so we got :1. no of hidden layers,2. no of units in each hidden layer,3. weights,\n",
        "#4. activation fn. \n",
        "#weights in general are initialised randomly. But it is\n",
        "#not neccesary to initialise weights in keras."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "51y_PCGGAh8c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Definitions: **"
      ]
    },
    {
      "metadata": {
        "id": "g6ikxxDxujfD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#definitions:\n",
        "#units: very similar to k*k filter in cnn\n",
        "\n",
        "#weights: read in neural network when we do layer 1 to layer 2 then m1x1+m2x2+m3\n",
        "#m1, m2 etc were weights m3 was bias, on individual units mapping , m1, m2 etc were\n",
        "#weights getting multiplied by units xx1,x2 etc.\n",
        "\n",
        "#layers:\n",
        "#input layer, convolution layers, pooling layers, hidden layers, output layer in cnn\n",
        "#input layer , hidden layers, output layer in simple neural network/tensorflow\n",
        "\n",
        "#activation fn : read already."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hN6MxnxPx58G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jWD368nqx9Fp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#these hidden layers are called dense layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IV0ioYVPyCf_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense  #to import dense layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QOTfl-HjyMZT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layer1=Dense(units=32, activation='relu', input_dim=30) \n",
        "model.add(layer1)\n",
        "\n",
        "#to create a dense layer/hidden layer with \n",
        "#32 units and activation fn=relu, the input layer for this hidden layer1 has 30 units"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WNOOVGLtywvL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#there another way,we can add a layer directly to model also like, we can add hidden layer 2 by:\n",
        "\n",
        "model.add(Dense(units=16,activation='relu'))  \n",
        "#second hidden/dense layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5SKrZzCazF8C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(units=1,activation='sigmoid'))   \n",
        "#adding output layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iBkYfAlrItF5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qnZPnS-GItIf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rT9E1DP5_rXw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**How to decide number of input, hidden, output layers and number of units in each layer.\n",
        "**"
      ]
    },
    {
      "metadata": {
        "id": "bJQZgn_U_mKB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#here we are calling the units in hidden layers/neural network layer as neurons\n",
        "\n",
        "# The Input Layer\n",
        "\n",
        "# Simple--every NN has exactly one of them--no exceptions that I'm aware of.\n",
        "\n",
        "# With respect to the number of neurons comprising this layer, \n",
        "# this parameter is completely and uniquely determined once you know the shape \n",
        "# of your training data. Specifically, the number of neurons comprising that layer\n",
        "# is equal to the number of features (columns) in your data. \n",
        "# Some NN configurations add one additional node for a bias term.\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OKE5U4Sm_oRf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The Output Layer\n",
        "\n",
        "# Like the Input layer, every NN has exactly one output layer.\n",
        "# Determining its size (number of neurons) is simple; \n",
        "# it is completely determined by the chosen model configuration.\n",
        "\n",
        "# Is your NN going running in Machine Mode or Regression Mode \n",
        "# (the ML convention of using a term that is also used in statistics but a\n",
        "#  ssigning a different meaning to it is very confusing). \n",
        "# Machine mode: returns a class label\n",
        "#   (e.g., \"Premium Account\"/\"Basic Account\"). \n",
        "#   Regression Mode returns a value (e.g., price).\n",
        "\n",
        "# If the NN is a regressor, then the output layer has a single node.\n",
        "\n",
        "# If the NN is a classifier, then it also has a single node \n",
        "# unless softmax(type of activation) is used in which case the output layer\n",
        "# has one node per class label in your model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5UPjwrsk_ouP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The Hidden Layers\n",
        "\n",
        "# How many hidden layers? Well if your data is linearly separable \n",
        "# (which you often know by the time you begin coding a NN) \n",
        "# then you don't need any hidden layers at all. Of course,\n",
        "# you don't need an NN to resolve your data either, \n",
        "# but it will still do the job.\n",
        "\n",
        "# One issue within this subject on which there is a consensus is the performance \n",
        "# difference from adding additional hidden layers:\n",
        "#   the situations in which performance improves with a second (or third, etc.) \n",
        "#   hidden layer are very few. One hidden layer is sufficient for the\n",
        "#   large majority of problems.\n",
        "\n",
        "# So what about size of the hidden layer(s)\n",
        "# --how many neurons? There are some empirically-derived rules-of-thumb,\n",
        "# of these, the most commonly relied on is\n",
        "# 'the optimal size of the hidden layer is usually between \n",
        "# the size of the input and size of the output layers'. \n",
        "# Jeff Heaton, author of Introduction to Neural Networks in Java \n",
        "# offers a few more.\n",
        "\n",
        "#In sum, for most problems, one could probably get decent \n",
        "#performance (even without a second optimization step) by setting the\n",
        "#hidden layer configuration using just two rules: \n",
        "#(i) number of hidden layers equals one; and \n",
        "#(ii) the number of neurons in that layer is the mean of the \n",
        "#neurons in the input and output layers. eg here no of hidden layer=1\n",
        "#no of neuron in layer = (30+1)/2 means keeping just one layer with \n",
        "#16 units was also good enough\n",
        "\n",
        "#here's one additional rule of thumb that helps for supervised \n",
        "#learning problems. The upper bound on the number of hidden neurons that\n",
        "#won't result in over-fitting is:\n",
        "\n",
        "#No of neurons in hidden layer =No of sample/(a * (No of neurons in input layer+ Number of neurons in output layer))\n",
        "\n",
        "#ùõº = an arbitrary scaling factor usually 2-10.\n",
        "\n",
        "#eg in our case, no of sample/no of rows=569, input+output=30+1\n",
        "#take a =2.\n",
        "#So n= 569/(2*31) neurons in hidden will be good enough\n",
        "\n",
        "#Others recommend setting ùëéùëôùëù‚Ñéùëé to a value between 5 and 10,\n",
        "#but I find a value of 2 will often work without overfitting.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BiT9uDZe-I-u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The Number of Hidden Layers\n",
        "\n",
        "# There are really two decisions that must be made regarding the hidden layers:\n",
        "#   how many hidden layers to actually have in the neural network and\n",
        "#   how many neurons will be in each of these layers. \n",
        "#   We will first examine how to determine the number of hidden layers to use\n",
        "#   with the neural network.\n",
        "\n",
        "# Problems that require two hidden layers are rarely encountered.\n",
        "# However, neural networks with two hidden layers can represent functions \n",
        "# with any kind of shape. There is currently no theoretical reason to use \n",
        "# neural networks with any more than two hidden layers. \n",
        "# In fact, for many practical problems, there is no reason to use\n",
        "# any more than one hidden layer. Table 5.1 summarizes the capabilities of \n",
        "# neural network architectures with various hidden layers.\n",
        "\n",
        "# | Number of Hidden Layers | Result |\n",
        "\n",
        "#  0 - Only capable of representing linear separable functions or decisions.\n",
        "\n",
        "#  1 - Can approximate any function that contains a continuous mapping\n",
        "# from one finite space to another.\n",
        "\n",
        "#  2 - Can represent an arbitrary decision boundary to arbitrary accuracy\n",
        "# with rational activation functions and can approximate any smooth\n",
        "# mapping to any accuracy.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# There are many rule-of-thumb methods for determining the correct number of neurons to use in the hidden layers, such as the following:\n",
        "\n",
        "# The number of hidden neurons should be between the size of the input layer and the size of the output layer.\n",
        "# The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\n",
        "# The number of hidden neurons should be less than twice the size of the input layer.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bpJqGm_8-JCp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ETV1c9U0-JF7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A564xUgSGseC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**What is optimizer? what optimzers we can use ?**"
      ]
    },
    {
      "metadata": {
        "id": "bkfLMwi7-JJE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Optimizers is basically to improve efficency of ur neural network. Just \n",
        "# like we use gradient descent, stochastic and batch gradient . They were\n",
        "# also optimzers. Similarly in neural networks we have other optimizers."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_9JdKsfL-JMW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#see this documentation on optimzers , to chose different optimizer,\n",
        "#how each works etc, how to use.\n",
        "#it also has defaut and best value for each parameter of optimizer.\n",
        "# https://keras.io/optimizers/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u6ttSG_lHe9L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "50qZPDxiHcZU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J1HPHBQcI3HL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**coming back to breast_cancer code**"
      ]
    },
    {
      "metadata": {
        "id": "yuUt48Mbyq-O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#compiling step, need 3 things:\n",
        "#1. need to tell which optimizer to use: adam, sgd, adagrad etc\n",
        "#2.which loss fn to use: mean square error in regression problem,\n",
        "#cross entropy in classifier problem generally.\n",
        "#3. metrics: print metrics after each step like accuracy , loss etc\n",
        "\n",
        "#read documentation of keras to decide what and how to use."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RH9FmYsUJrL5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sM0x4k7YJ4xq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#used adam optimizer, since output has binary class , and its classification problem\n",
        "#so used binary_crossentropy as loss fn, metrics we want to print in each step\n",
        "#is accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MMm5Vjy5KWwe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zP463EtdJk8I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#fitting step:\n",
        "#we need to pass 3 things to fit fn\n",
        "#1. x\n",
        "#2. y\n",
        "#3. epochs\n",
        "#4. batch size\n",
        "#5.Validation data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uzy2Hi3Yypbw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uqHvzplqL3ew",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**What are epochs? **"
      ]
    },
    {
      "metadata": {
        "id": "FpE5U1rIyffc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# epochs is the number of times u want to run the iterations: i.e no of times\n",
        "#   u want to do forward and backward propagation. by default epochs=1\n",
        "#   but u should keep epochs 40-50etc atleast"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0xSmAc5Eq4yw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Far296ruMZnD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**What is batch size**"
      ]
    },
    {
      "metadata": {
        "id": "-bvPyzRhqJEZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# if u want to update the weights as in gradient descent , we can do it\n",
        "# in batches , default batch size is 32. If u keep epochs=40 , batch size=50\n",
        "# and no of samples is 1000, then in each epoch it will not update all 1000\n",
        "# sample at once , it will do in batch of 50."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kEdnWUbkNHIk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b5CrSj6DNIa9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**What is validation data?**"
      ]
    },
    {
      "metadata": {
        "id": "1WeLDH9QNHi1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# It is an arguement we pass in fit fn.\n",
        "# U can pass our test data as validation data, so that when we can print accuracy\n",
        "# in each step, our accuracy , using test data as reference.\n",
        "# Validation data is just for accuracy , not used in traing !"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4moOaIbPNo0S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZnFWeNDdNrt-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lEZvfvA_NsZ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**coming back to breast_cancer code**"
      ]
    },
    {
      "metadata": {
        "id": "xjDhodVkNv7n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FcD41L_hNywp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwHNGZGpN8QQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(breastCancer.data,breastCancer.target,test_size=0.2,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iXBNqz0fOQmD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#scaling the data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ASryqWpDOZDR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bvmw4BkDOh8Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sc=StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GZjqDCLnOkgX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train=sc.fit_transform(x_train)\n",
        "x_test=sc.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y3Rr9UAtOqqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c74dba49-6ab2-4aa6-cf6e-a67b2622eef9"
      },
      "cell_type": "code",
      "source": [
        "# model.fit(x_train,y_train)   \n",
        "#by default epoch=1, accuracy came to be 0.53"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "455/455 [==============================] - 1s 1ms/step - loss: 0.6947 - acc: 0.5385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a871a7ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "qxZfvRlTOwLV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#to run for multiple epoch to improve accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zEvPEodNO-Q6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "cc6f527a-0d2d-4c88-b924-27df2b55012b"
      },
      "cell_type": "code",
      "source": [
        "# model.fit(x_train,y_train,epochs=20)  \n",
        "#we can see accuracy has improved to 0.98"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "455/455 [==============================] - 0s 55us/step - loss: 0.5178 - acc: 0.8462\n",
            "Epoch 2/20\n",
            "455/455 [==============================] - 0s 52us/step - loss: 0.4070 - acc: 0.9231\n",
            "Epoch 3/20\n",
            "455/455 [==============================] - 0s 51us/step - loss: 0.3127 - acc: 0.9473\n",
            "Epoch 4/20\n",
            "455/455 [==============================] - 0s 50us/step - loss: 0.2406 - acc: 0.9538\n",
            "Epoch 5/20\n",
            "455/455 [==============================] - 0s 52us/step - loss: 0.1894 - acc: 0.9626\n",
            "Epoch 6/20\n",
            "455/455 [==============================] - 0s 54us/step - loss: 0.1534 - acc: 0.9670\n",
            "Epoch 7/20\n",
            "455/455 [==============================] - 0s 50us/step - loss: 0.1294 - acc: 0.9736\n",
            "Epoch 8/20\n",
            "455/455 [==============================] - 0s 50us/step - loss: 0.1124 - acc: 0.9736\n",
            "Epoch 9/20\n",
            "455/455 [==============================] - 0s 51us/step - loss: 0.0997 - acc: 0.9736\n",
            "Epoch 10/20\n",
            "455/455 [==============================] - 0s 57us/step - loss: 0.0897 - acc: 0.9736\n",
            "Epoch 11/20\n",
            "455/455 [==============================] - 0s 47us/step - loss: 0.0820 - acc: 0.9736\n",
            "Epoch 12/20\n",
            "455/455 [==============================] - 0s 50us/step - loss: 0.0762 - acc: 0.9780\n",
            "Epoch 13/20\n",
            "455/455 [==============================] - 0s 53us/step - loss: 0.0717 - acc: 0.9780\n",
            "Epoch 14/20\n",
            "455/455 [==============================] - 0s 44us/step - loss: 0.0678 - acc: 0.9802\n",
            "Epoch 15/20\n",
            "455/455 [==============================] - 0s 54us/step - loss: 0.0638 - acc: 0.9846\n",
            "Epoch 16/20\n",
            "455/455 [==============================] - 0s 51us/step - loss: 0.0610 - acc: 0.9868\n",
            "Epoch 17/20\n",
            "455/455 [==============================] - 0s 66us/step - loss: 0.0584 - acc: 0.9890\n",
            "Epoch 18/20\n",
            "455/455 [==============================] - 0s 49us/step - loss: 0.0559 - acc: 0.9890\n",
            "Epoch 19/20\n",
            "455/455 [==============================] - 0s 46us/step - loss: 0.0538 - acc: 0.9890\n",
            "Epoch 20/20\n",
            "455/455 [==============================] - 0s 48us/step - loss: 0.0519 - acc: 0.9890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a87b8cc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "JfXN443JPLTS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#by default batch_size was 32, if u pass nothing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M4jT9IVtNwQV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#we can use diff batch sizes also"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jBHd5y9LPauV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "dd786fc0-2fdc-4e48-8211-19421bfb3377"
      },
      "cell_type": "code",
      "source": [
        "# model.fit(x_train,y_train,epochs=20,batch_size=50)\n",
        "\n",
        "#run all cells from top (start from where u intialised model to bottom) , to see diff that after\n",
        "#adding each new paramter in fn\n",
        "\n",
        "#here accuracy u r seeing , is accuracy on training data"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "455/455 [==============================] - 0s 49us/step - loss: 0.0502 - acc: 0.9890\n",
            "Epoch 2/20\n",
            "455/455 [==============================] - 0s 48us/step - loss: 0.0490 - acc: 0.9890\n",
            "Epoch 3/20\n",
            "455/455 [==============================] - 0s 39us/step - loss: 0.0481 - acc: 0.9912\n",
            "Epoch 4/20\n",
            "455/455 [==============================] - 0s 39us/step - loss: 0.0475 - acc: 0.9890\n",
            "Epoch 5/20\n",
            "455/455 [==============================] - 0s 39us/step - loss: 0.0466 - acc: 0.9912\n",
            "Epoch 6/20\n",
            "455/455 [==============================] - 0s 38us/step - loss: 0.0458 - acc: 0.9912\n",
            "Epoch 7/20\n",
            "455/455 [==============================] - 0s 37us/step - loss: 0.0443 - acc: 0.9912\n",
            "Epoch 8/20\n",
            "455/455 [==============================] - 0s 37us/step - loss: 0.0433 - acc: 0.9912\n",
            "Epoch 9/20\n",
            "455/455 [==============================] - 0s 37us/step - loss: 0.0424 - acc: 0.9912\n",
            "Epoch 10/20\n",
            "455/455 [==============================] - 0s 43us/step - loss: 0.0417 - acc: 0.9912\n",
            "Epoch 11/20\n",
            "455/455 [==============================] - 0s 38us/step - loss: 0.0411 - acc: 0.9912\n",
            "Epoch 12/20\n",
            "455/455 [==============================] - 0s 40us/step - loss: 0.0402 - acc: 0.9912\n",
            "Epoch 13/20\n",
            "455/455 [==============================] - 0s 44us/step - loss: 0.0395 - acc: 0.9912\n",
            "Epoch 14/20\n",
            "455/455 [==============================] - 0s 42us/step - loss: 0.0393 - acc: 0.9912\n",
            "Epoch 15/20\n",
            "455/455 [==============================] - 0s 47us/step - loss: 0.0388 - acc: 0.9912\n",
            "Epoch 16/20\n",
            "455/455 [==============================] - 0s 38us/step - loss: 0.0380 - acc: 0.9912\n",
            "Epoch 17/20\n",
            "455/455 [==============================] - 0s 37us/step - loss: 0.0371 - acc: 0.9912\n",
            "Epoch 18/20\n",
            "455/455 [==============================] - 0s 37us/step - loss: 0.0363 - acc: 0.9912\n",
            "Epoch 19/20\n",
            "455/455 [==============================] - 0s 32us/step - loss: 0.0360 - acc: 0.9912\n",
            "Epoch 20/20\n",
            "455/455 [==============================] - 0s 44us/step - loss: 0.0344 - acc: 0.9912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a87059438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "CNj71oYIP_q7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#we can pass validation_data also"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TKXhqLrMQNTY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "7a4e168b-8a7d-4553-f67a-4009820c3580"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,epochs=20,batch_size=50,validation_data=(x_test,y_test))\n",
        "\n",
        "#now we can see accuracy on both training data(lhs) and testing data as well(rhs).\n",
        "#accuracy on training data=0.99 , on test data =0.97"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 455 samples, validate on 114 samples\n",
            "Epoch 1/20\n",
            "455/455 [==============================] - 0s 107us/step - loss: 0.0340 - acc: 0.9912 - val_loss: 0.0680 - val_acc: 0.9649\n",
            "Epoch 2/20\n",
            "455/455 [==============================] - 0s 39us/step - loss: 0.0344 - acc: 0.9912 - val_loss: 0.0682 - val_acc: 0.9649\n",
            "Epoch 3/20\n",
            "455/455 [==============================] - 0s 40us/step - loss: 0.0331 - acc: 0.9912 - val_loss: 0.0668 - val_acc: 0.9649\n",
            "Epoch 4/20\n",
            "455/455 [==============================] - 0s 40us/step - loss: 0.0320 - acc: 0.9912 - val_loss: 0.0660 - val_acc: 0.9649\n",
            "Epoch 5/20\n",
            "455/455 [==============================] - 0s 41us/step - loss: 0.0312 - acc: 0.9912 - val_loss: 0.0656 - val_acc: 0.9649\n",
            "Epoch 6/20\n",
            "455/455 [==============================] - 0s 36us/step - loss: 0.0305 - acc: 0.9912 - val_loss: 0.0654 - val_acc: 0.9649\n",
            "Epoch 7/20\n",
            "455/455 [==============================] - 0s 38us/step - loss: 0.0298 - acc: 0.9912 - val_loss: 0.0653 - val_acc: 0.9649\n",
            "Epoch 8/20\n",
            "455/455 [==============================] - 0s 41us/step - loss: 0.0291 - acc: 0.9912 - val_loss: 0.0650 - val_acc: 0.9649\n",
            "Epoch 9/20\n",
            "455/455 [==============================] - 0s 36us/step - loss: 0.0286 - acc: 0.9912 - val_loss: 0.0645 - val_acc: 0.9649\n",
            "Epoch 10/20\n",
            "455/455 [==============================] - 0s 37us/step - loss: 0.0283 - acc: 0.9912 - val_loss: 0.0644 - val_acc: 0.9649\n",
            "Epoch 11/20\n",
            "455/455 [==============================] - 0s 35us/step - loss: 0.0272 - acc: 0.9912 - val_loss: 0.0638 - val_acc: 0.9737\n",
            "Epoch 12/20\n",
            "455/455 [==============================] - 0s 37us/step - loss: 0.0270 - acc: 0.9912 - val_loss: 0.0633 - val_acc: 0.9737\n",
            "Epoch 13/20\n",
            "455/455 [==============================] - 0s 42us/step - loss: 0.0264 - acc: 0.9912 - val_loss: 0.0638 - val_acc: 0.9737\n",
            "Epoch 14/20\n",
            "455/455 [==============================] - 0s 37us/step - loss: 0.0259 - acc: 0.9912 - val_loss: 0.0641 - val_acc: 0.9737\n",
            "Epoch 15/20\n",
            "455/455 [==============================] - 0s 43us/step - loss: 0.0254 - acc: 0.9912 - val_loss: 0.0651 - val_acc: 0.9737\n",
            "Epoch 16/20\n",
            "455/455 [==============================] - 0s 39us/step - loss: 0.0249 - acc: 0.9912 - val_loss: 0.0651 - val_acc: 0.9737\n",
            "Epoch 17/20\n",
            "455/455 [==============================] - 0s 40us/step - loss: 0.0244 - acc: 0.9912 - val_loss: 0.0654 - val_acc: 0.9737\n",
            "Epoch 18/20\n",
            "455/455 [==============================] - 0s 39us/step - loss: 0.0242 - acc: 0.9912 - val_loss: 0.0642 - val_acc: 0.9737\n",
            "Epoch 19/20\n",
            "455/455 [==============================] - 0s 38us/step - loss: 0.0243 - acc: 0.9912 - val_loss: 0.0639 - val_acc: 0.9737\n",
            "Epoch 20/20\n",
            "455/455 [==============================] - 0s 39us/step - loss: 0.0236 - acc: 0.9912 - val_loss: 0.0645 - val_acc: 0.9737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a83003828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "ZpymAauCQUha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#to improve accuracy further we can use regularisation , using keras->documentation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wItS9UuwRGkW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rTyrfyrHRVtg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uSWmHQyDRVx6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#prediction and evaluation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hte-gm7vRYIi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1955
        },
        "outputId": "07d363d5-196d-4410-fd73-44136a91c52b"
      },
      "cell_type": "code",
      "source": [
        "predictions=model.predict(x_test)\n",
        "predictions      #3e-04 ->3 * 10 raise -4 means 0.0003 ,i.e 0 almost\n",
        "#9.99e-01 means 9* 10 raise -1 mean 0.9 means 1 almost(class 2)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.7908554e-04],\n",
              "       [9.0930331e-01],\n",
              "       [9.9984086e-01],\n",
              "       [9.9565470e-01],\n",
              "       [9.9983490e-01],\n",
              "       [9.9959636e-01],\n",
              "       [9.9996203e-01],\n",
              "       [9.9963248e-01],\n",
              "       [9.9984139e-01],\n",
              "       [9.9999774e-01],\n",
              "       [1.3360757e-01],\n",
              "       [9.0938199e-01],\n",
              "       [9.9995273e-01],\n",
              "       [3.9876467e-01],\n",
              "       [6.1672926e-01],\n",
              "       [3.5178661e-04],\n",
              "       [9.9924588e-01],\n",
              "       [0.0000000e+00],\n",
              "       [1.0728836e-06],\n",
              "       [0.0000000e+00],\n",
              "       [4.1061640e-04],\n",
              "       [2.0244718e-04],\n",
              "       [9.9885559e-01],\n",
              "       [9.9859023e-01],\n",
              "       [1.0728836e-05],\n",
              "       [9.9989575e-01],\n",
              "       [9.9996877e-01],\n",
              "       [1.8514693e-03],\n",
              "       [9.9971527e-01],\n",
              "       [1.1920929e-07],\n",
              "       [9.9994379e-01],\n",
              "       [4.0829182e-06],\n",
              "       [9.6464384e-01],\n",
              "       [1.2519956e-04],\n",
              "       [9.9999714e-01],\n",
              "       [1.5130639e-04],\n",
              "       [9.9602842e-01],\n",
              "       [2.8520823e-05],\n",
              "       [9.9820215e-01],\n",
              "       [1.2615323e-04],\n",
              "       [1.6620338e-02],\n",
              "       [9.9991107e-01],\n",
              "       [2.2301733e-02],\n",
              "       [9.9991167e-01],\n",
              "       [9.9442720e-01],\n",
              "       [0.0000000e+00],\n",
              "       [9.9999589e-01],\n",
              "       [9.7393692e-01],\n",
              "       [9.9988103e-01],\n",
              "       [1.6391277e-06],\n",
              "       [2.3841858e-06],\n",
              "       [1.7116129e-02],\n",
              "       [2.0861626e-06],\n",
              "       [9.9970531e-01],\n",
              "       [9.9879676e-01],\n",
              "       [9.9988115e-01],\n",
              "       [9.9926651e-01],\n",
              "       [9.9893570e-01],\n",
              "       [9.8937094e-01],\n",
              "       [0.0000000e+00],\n",
              "       [2.9796362e-04],\n",
              "       [1.5020370e-04],\n",
              "       [9.9997735e-01],\n",
              "       [9.9940091e-01],\n",
              "       [2.2679567e-05],\n",
              "       [9.5458448e-01],\n",
              "       [0.0000000e+00],\n",
              "       [5.9604645e-08],\n",
              "       [2.9802322e-08],\n",
              "       [9.9955809e-01],\n",
              "       [6.9262105e-01],\n",
              "       [3.5762787e-07],\n",
              "       [9.9947149e-01],\n",
              "       [7.0004076e-02],\n",
              "       [5.9604645e-08],\n",
              "       [9.4455600e-01],\n",
              "       [9.9998045e-01],\n",
              "       [9.9641168e-01],\n",
              "       [9.9980599e-01],\n",
              "       [9.9970984e-01],\n",
              "       [1.4163852e-03],\n",
              "       [0.0000000e+00],\n",
              "       [2.6822090e-07],\n",
              "       [9.9991405e-01],\n",
              "       [1.1896491e-03],\n",
              "       [9.9996483e-01],\n",
              "       [9.9997628e-01],\n",
              "       [9.9999332e-01],\n",
              "       [2.8312206e-06],\n",
              "       [0.0000000e+00],\n",
              "       [9.9999195e-01],\n",
              "       [4.4123814e-01],\n",
              "       [6.5924478e-01],\n",
              "       [1.4901161e-07],\n",
              "       [9.9935484e-01],\n",
              "       [9.9934781e-01],\n",
              "       [0.0000000e+00],\n",
              "       [9.9836111e-01],\n",
              "       [9.9686658e-01],\n",
              "       [9.9849713e-01],\n",
              "       [9.9999750e-01],\n",
              "       [9.9831688e-01],\n",
              "       [9.9702024e-01],\n",
              "       [9.8258322e-01],\n",
              "       [2.4437904e-06],\n",
              "       [9.9937773e-01],\n",
              "       [0.0000000e+00],\n",
              "       [8.3530247e-01],\n",
              "       [2.6614255e-01],\n",
              "       [6.8684000e-01],\n",
              "       [9.9218470e-01],\n",
              "       [2.0861626e-07],\n",
              "       [2.4946169e-06],\n",
              "       [7.0788521e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "metadata": {
        "id": "ATNYn_hpRi0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8e0199f9-d1bd-4d66-c8cc-1e9b134aae8b"
      },
      "cell_type": "code",
      "source": [
        "score=model.evaluate(x_test,y_test)\n",
        "score  #loss, accuracy"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "114/114 [==============================] - 0s 54us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06446244946697302, 0.9736842063435337]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "AeFor7tWSIfJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYTmXsrTNwxT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tROotTkxSWiN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Using keras for cnn**"
      ]
    },
    {
      "metadata": {
        "id": "SxCY8-BUSaDS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "osY_fDqHS2I-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#reshape images\n",
        "#read documentation or see eg , how to use keras for cnn or how to use keras\n",
        "#on mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5T_TX-CFTP-B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#use drop-out layer for regularisation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uRsaWYA3TVJG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#flatten data before using dense layer.  there is flatten() fn or layer\n",
        "#for this"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9TJuYNEjTfvd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f52e5c33-24fb-4543-8762-1f1668bfeeb3"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "data=mnist.load_data()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pILXF77OU8_0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        },
        "outputId": "06e49c88-7a2a-4136-9e27-c3a80f1a6ec9"
      },
      "cell_type": "code",
      "source": [
        "data"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         ...,\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
              "  array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)),\n",
              " (array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         ...,\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
              "  array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "0gqNYRY5U-M2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AYCi1Mu0TY6k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test)=data  #since data was in form of this 2d array\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZJV4wHZwVIKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PFiF7V7BVk1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "909fd741-3bdd-4ace-de30-b9874ff6de7e"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4a822a19e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "tVBOET37Vnye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "6bab2c2c-8b2d-4c03-a083-c063ad0dee73"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[1])"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4a8022c9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBoAg/EBThB4Ii/EBQhB8I6v8AG8x2aarNGp8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "jd2Qe0DkVrZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "40a9a398-673f-4246-da11-0ddf7d3b5dae"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[2])"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4a82361ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "-nVQVf2TVuGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "ed3d61b3-7b55-42de-e170-5b8aca0392de"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[3])"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4a801c8908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8EtFGX6pKMMvFWX4paL+H5OL6YVERhITAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ci3823O4Vvx-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ab9MwyrsVQwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5169711-e5bc-4e5c-f7a9-febe87ddea1e"
      },
      "cell_type": "code",
      "source": [
        "X_train[0].shape   #i.e 28 by 28 pixels"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "metadata": {
        "id": "FG7Jd3QrVzzi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#so reshape to rgb form 28*28*1, since Xtrain has 60,000 img, X_test has\n",
        "#10,000 img so"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KtF1NEJqWDQj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train=X_train.reshape(60000,28,28,1)\n",
        "X_test=X_test.reshape(10000,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KVtaDSDyWPRk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NoXbhqACWVJ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#one hot encode target column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uw8_rTdMWYJU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train= to_categorical(y_train)\n",
        "y_test=to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oDlp1UfHWenv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "865cd393-6a24-42c0-f1a0-133eed1e0d05"
      },
      "cell_type": "code",
      "source": [
        "y_train[0]    #one hot encoded"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "metadata": {
        "id": "eSdL6SncWgWn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FbMoQirRVOcG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Now building the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwnyr-yfWlWC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VARbx1S2Woaj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Conv2D,Flatten\n",
        "\n",
        "#since for using keras \n",
        "#for cnn, we need hidden layer/dense layer as usual , + we need convolution layer\n",
        "# i.e Conv2D, also we need Flatten layer to flatten these images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6WtGtQ7UW_LG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UIcq4NcCXB3Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#no of units in convolution layer1= 64, activation fn=relu, input layer for\n",
        "#this layer is a image of size 28*28*1, filter size is 3 * 3, i.e kernel size=3\n",
        "\n",
        "model.add(Conv2D(64,kernel_size=3,activation='relu',input_shape=(28,28,1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KqiaIdKtXOiJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#similary adding second convolution layer with 32 units\n",
        "\n",
        "model.add(Conv2D(32,kernel_size=3,activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UdK-LepmXs9A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tV0e-iGaXxj3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(10,activation='softmax'))   #adding hidden/dense layer with\n",
        "#activation fn as softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zfy4UEPMX2nW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k5_T9QVUYHzd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d0d754da-ef45-47c0-8489-f56fdae42145"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=3)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 208s 3ms/step - loss: 0.1327 - acc: 0.9611 - val_loss: 0.0901 - val_acc: 0.9733\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 210s 3ms/step - loss: 0.0625 - acc: 0.9813 - val_loss: 0.0747 - val_acc: 0.9779\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 208s 3ms/step - loss: 0.0448 - acc: 0.9862 - val_loss: 0.0809 - val_acc: 0.9781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a80162b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "metadata": {
        "id": "c73GzQviYXaN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ipY0ce0YRBe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sp_yxm61W-VK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PNnYLlIAWtZw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0SiF-cICVLik",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wLTUvD4GS9gQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HeIo33lfSlKn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f6xAqAG1SlUO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}