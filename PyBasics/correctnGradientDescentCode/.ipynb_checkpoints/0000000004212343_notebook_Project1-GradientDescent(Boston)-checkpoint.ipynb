{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(x, y, learning_rate, m):\n",
    "    k = x.shape[0]\n",
    "    l = x.shape[1]\n",
    "    slope_m = np.zeros(l)\n",
    "    for i in range(k):\n",
    "        for j in range(l):\n",
    "            slope_m[j] += (2/k)*x[i][j]*((x[i].dot(m)) - y[i])\n",
    "        #if i%32 == 0:\n",
    "    m = m - learning_rate*slope_m\n",
    "            #slope_m = np.zeros(l)\n",
    "    return m\n",
    "\n",
    "def cost(x, y, m):\n",
    "    return ((y-(x.dot(m)))**2).mean()\n",
    "\n",
    "def gradient_descent(x,y, learning_rate, num_iter):\n",
    "    m = np.zeros(x.shape[1])\n",
    "    print('start: ', cost(x,y,m))\n",
    "    for i in range(num_iter):\n",
    "        m = step_gradient(x,y, learning_rate, m)\n",
    "        if i%10 == 0:\n",
    "            print(i, \" : \", cost(x,y,m))\n",
    "    return m\n",
    "\n",
    "def run(x,y):\n",
    "    learning_rate = 0.01\n",
    "    num_iter = 380\n",
    "    m = gradient_descent(x,y,learning_rate,num_iter)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-71-259070d1a9ca>, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-71-259070d1a9ca>\"\u001b[1;36m, line \u001b[1;32m30\u001b[0m\n\u001b[1;33m    x_train = scaler.fit_transform(x_train)\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dataset = np.genfromtxt('training_boston_x_y_train.csv', delimiter=',')\n",
    "x_train = dataset[:,:-1]\n",
    "y_train = dataset[:,-1]\n",
    "x_test = np.genfromtxt('test_boston_x_test.csv', delimiter=',')\n",
    "df_train = pd.DataFrame(x_train)\n",
    "df_test = pd.DataFrame(x_test)\n",
    "\n",
    "i = 0\n",
    "n = len(df_train.columns)\n",
    "l = df_train.columns\n",
    "while i < n:\n",
    "    j = i\n",
    "    while j < n:\n",
    "        df_train[str(l[i]) + '*' + str(l[j])] = df_train[l[i]]*df_train[l[j]]\n",
    "        j += 1\n",
    "    i += 1\n",
    "    \n",
    "i = 0\n",
    "n = len(df_test.columns)\n",
    "l = df_test.columns\n",
    "while i < n:\n",
    "    j = i\n",
    "    while j < n:\n",
    "        df_test[str(l[i]) + '*' + str(l[j])] = df_test[l[i]]*df_test[l[j]]\n",
    "        j += 1\n",
    "    i += 1\n",
    "\n",
    "x_train = np.array(df_train)\n",
    "x_test = np.array(scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# for i in range(len(x_train[0])):\n",
    "#     std = np.sqrt(((x_train[:,i] - x_train[:,i].mean())**2).mean())\n",
    "#     x_train[:, i] = (x_train[:, i] - x_train[:, i].mean())/ std\n",
    "\n",
    "# for i in range(len(x_test[0])):\n",
    "#     std = np.sqrt(((x_test[:,i] - x_test[:,i].mean())**2).mean())\n",
    "#     x_test[:, i] = (x_test[:, i] - x_test[:, i].mean())/ std\n",
    "\n",
    "#for i in range(len(x_train[0])):\n",
    "#    x_train[:, i] = (x_train[:, i] - x_train[:, i].mean()) / (max(x_train[:, i]) - min(x_train[:, i]))\n",
    "    \n",
    "#for i in range(len(x_test[0])):\n",
    "#    x_test[:, i] = (x_test[:, i] - x_test[:, i].mean()) / (max(x_test[:, i]) - min(x_test[:, i]))\n",
    "\n",
    "#for i in range(len(x_train[0])):\n",
    "#    x_train[:, i] = (x_train[:, i] - min(x_train[:, i])) / (max(x_train[:, i]) - min(x_train[:, i]))\n",
    "    \n",
    "#for i in range(len(x_test[0])):\n",
    "#    x_test[:, i] = (x_test[:, i] - min(x_test[:, i])) / (max(x_test[:, i]) - min(x_test[:, i]))\n",
    "\n",
    "# x_train = preprocessing.scale(x_train)\n",
    "# x_test = preprocessing.scale(x_test)df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# for i in range(len(x_train[0])):\n",
    "#     std = np.sqrt(((x_train[:,i] - x_train[:,i].mean())**2).mean())\n",
    "#     x_train[:, i] = (x_train[:, i] - x_train[:, i].mean())/ std\n",
    "\n",
    "# for i in range(len(x_test[0])):\n",
    "#     std = np.sqrt(((x_test[:,i] - x_test[:,i].mean())**2).mean())\n",
    "#     x_test[:, i] = (x_test[:, i] - x_test[:, i].mean())/ std\n",
    "\n",
    "#for i in range(len(x_train[0])):\n",
    "#    x_train[:, i] = (x_train[:, i] - x_train[:, i].mean()) / (max(x_train[:, i]) - min(x_train[:, i]))\n",
    "    \n",
    "#for i in range(len(x_test[0])):\n",
    "#    x_test[:, i] = (x_test[:, i] - x_test[:, i].mean()) / (max(x_test[:, i]) - min(x_test[:, i]))\n",
    "\n",
    "#for i in range(len(x_train[0])):\n",
    "#    x_train[:, i] = (x_train[:, i] - min(x_train[:, i])) / (max(x_train[:, i]) - min(x_train[:, i]))\n",
    "    \n",
    "#for i in range(len(x_test[0])):\n",
    "#    x_test[:, i] = (x_test[:, i] - min(x_test[:, i])) / (max(x_test[:, i]) - min(x_test[:, i]))\n",
    "\n",
    "# x_train = preprocessing.scale(x_train)\n",
    "# x_test = preprocessing.scale(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.insert(x_train, 0, 1, axis = 1)\n",
    "x_test = np.insert(x_test, 0, 1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  599.1222691292876\n",
      "0  :  561.230092906007\n",
      "10  :  356.51318994763415\n",
      "20  :  239.96031200167437\n",
      "30  :  164.1159022293201\n",
      "40  :  113.7459344571091\n",
      "50  :  80.08207379052847\n",
      "60  :  57.50746769038039\n",
      "70  :  42.32617469914688\n",
      "80  :  32.0854935513023\n",
      "90  :  25.151982626350133\n",
      "100  :  20.43572170211394\n",
      "110  :  17.20851612568289\n",
      "120  :  14.983330180178749\n",
      "130  :  13.434088576805209\n",
      "140  :  12.342239044390615\n"
     ]
    }
   ],
   "source": [
    "m = run(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = x_test.dot(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('boston_y_pred.csv', y_pred, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
